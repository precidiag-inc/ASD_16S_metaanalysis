{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9271e459-5598-4043-8a59-c7db925f42a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from utils import UnityScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d5345ef-2efe-47bd-b104-09644170245c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erxw/PycharmProjects/ASD_16S_metaanalysis/ASD_16S_metaanalysis/Figure 5/../utils/_unity.py:15: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  df /= np.sum(df, axis = self.axis)[:, None]\n"
     ]
    }
   ],
   "source": [
    "reads_threshold = 6000\n",
    "\n",
    "data_directory = '../data/'\n",
    "data_filename = 'metaanalysis_data.pickle'\n",
    "metadata_filename = 'metaanalysis_metadata.pickle' \n",
    "\n",
    "data = pickle.load(open(os.path.join(data_directory, data_filename), 'rb'))\n",
    "metadata = pickle.load(open(os.path.join(data_directory, metadata_filename), 'rb'))\n",
    "\n",
    "# remove samples with fewer than reads_threshold \n",
    "data = data.loc[data.sum(axis = 1) >= reads_threshold]\n",
    "metadata = metadata.loc[data.index]\n",
    "\n",
    "# label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "metadata['Status'] = label_encoder.fit_transform(metadata['Status'])\n",
    "\n",
    "# normalize each sample\n",
    "data = UnityScaler().fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8775a23b-2aa6-41a9-9353-7fe2afc9c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['Status'] = 1 - metadata['Status']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd6af2d7-d8dc-4b46-9b0c-f2dab6850315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "repeats = 50\n",
    "colors = ['#CE3534', '#741B47', '#1F78B4']\n",
    "\n",
    "scores = {}\n",
    "\n",
    "def get_tpr(x, y , repeats = 5):\n",
    "    fpr_mean = np.linspace(0, 1, 100)\n",
    "    tprs, aucs, accuracy, f1 = [], [], [], []\n",
    "    for train_index, test_index in RepeatedKFold(n_splits = 5, n_repeats = repeats, random_state = 1).split(y):\n",
    "        try:\n",
    "\n",
    "            xtrain, xtest = x.iloc[train_index], x.iloc[test_index]\n",
    "            ytrain, ytest = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            model.fit(xtrain, ytrain)\n",
    "\n",
    "            fpr, tpr, threshold = roc_curve(ytest, model.predict_proba(xtest)[:, 1])\n",
    "            interp_tpr = np.interp(fpr_mean, fpr, tpr)\n",
    "            interp_tpr[0] = 0\n",
    "\n",
    "            tprs.append(interp_tpr)\n",
    "            aucs.append(roc_auc_score(ytest, model.predict(xtest)))\n",
    "            accuracy.append(accuracy_score(ytest, model.predict(xtest)))\n",
    "            f1.append(f1_score(ytest, model.predict(xtest)))\n",
    "        except:\n",
    "            continue\n",
    "    return np.array(tprs), np.array(aucs), np.array(accuracy), np.array(f1)\n",
    "    \n",
    "def plot(mean, sem, label, color):\n",
    "    plt.fill_between(np.linspace(0, 1, 100), mean - sem, mean + sem, alpha = 0.5, color = color)\n",
    "    plt.plot(np.linspace(0, 1, 100), mean, label = label, color = color)\n",
    "     \n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.legend(bbox_to_anchor = (1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6f9b1f-76fd-4cdd-a3d0-5a7129813834",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i, (group, df) in enumerate(metadata.groupby('Country')):\n",
    "    tprs, aucs, accuracy, f1 = get_tpr(data.loc[df.index], df['Status'], repeats)\n",
    "    scores['Country', group] = (aucs, accuracy, f1)\n",
    "    plot(np.mean(tprs,axis = 0), np.std(tprs, axis = 0) / np.sqrt(repeats), f'{group} (AUC = {np.mean(aucs):.2f})', colors[i])\n",
    "\n",
    "plt.savefig('Split_by_Country.pdf', dpi = 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590ec885-b1cb-423c-a4d6-036cea254388",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i, (group, df) in enumerate(metadata.groupby('Variable_Region')):\n",
    "    tprs, aucs, accuracy, f1 = get_tpr(data.loc[df.index], df['Status'], repeats)\n",
    "    scores['Variable_Region', group] = (aucs, accuracy, f1)\n",
    "    plot(np.mean(tprs,axis = 0), np.std(tprs, axis = 0) / np.sqrt(repeats), f'{group} (AUC = {np.mean(aucs):.2f})', colors[i])\n",
    "\n",
    "\n",
    "plt.savefig('Split_by_Variable_Region.pdf', dpi = 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0a3faf-b588-4ea9-a5e1-6ae3c86d0488",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i, (group, df) in enumerate(metadata.groupby('Sex')):\n",
    "    tprs, aucs, accuracy, f1 = get_tpr(data.loc[df.index], df['Status'], repeats)\n",
    "    scores['Sex', group] = (aucs, accuracy, f1)\n",
    "    plot(np.mean(tprs,axis = 0), np.std(tprs, axis = 0) / np.sqrt(repeats), f'{group} (AUC = {np.mean(aucs):.2f})', colors[i])\n",
    "\n",
    "\n",
    "plt.savefig('Split_by_Sex.pdf', dpi = 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a7d06d-b8e1-4855-aee5-ad8c69730cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i, (group, df) in enumerate(metadata.groupby('Control_relation')):\n",
    "    tprs, aucs, accuracy, f1 = get_tpr(data.loc[df.index], df['Status'], repeats)\n",
    "    scores['Control_relation', group] = (aucs, accuracy, f1)\n",
    "    plot(np.mean(tprs,axis = 0), np.std(tprs, axis = 0) / np.sqrt(repeats), f'{group} (AUC = {np.mean(aucs):.2f})', colors[i])\n",
    "\n",
    "\n",
    "plt.savefig('Split_by_relationship.pdf', dpi = 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834527d9-897a-46fe-a855-55629f12a76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i, (group, df) in enumerate(metadata.groupby('seq_depth_range')):\n",
    "    tprs, aucs, accuracy, f1 = get_tpr(data.loc[df.index], df['Status'], repeats)\n",
    "    scores['seq_depth_range', group] = (aucs, accuracy, f1)\n",
    "    plot(np.mean(tprs,axis = 0), np.std(tprs, axis = 0) / np.sqrt(repeats), f'{group} (AUC = {np.mean(aucs):.2f})', colors[i])\n",
    "\n",
    "\n",
    "plt.savefig('Split_by_seq_depth_range.pdf', dpi = 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cd22c1-b795-4d90-8250-3bee13e24df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['AUC', 'Accuracy', 'F1 Score']\n",
    "means = pd.concat([pd.Series({(k[0], k[1], metrics[i]) : a.mean() for i, a in enumerate(v)}) for k, v in scores.items()])\n",
    "sems = pd.concat([pd.Series({(k[0], k[1], metrics[i]) : a.std() /np.sqrt(repeats) for i, a in enumerate(v)}) for k, v in scores.items()])\n",
    "output = pd.concat([means, sems], axis = 1)\n",
    "output.columns = ['average', 'sem']\n",
    "output.to_csv('metadata metrics.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc057c2-b5c3-4f7a-b5af-e8ada5b3e2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
